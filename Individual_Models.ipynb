{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xlsxwriter\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from operator import itemgetter\n",
    "# !pip install pyclustering\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.utils.metric import type_metric, distance_metric\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Principal Components Analysis\n",
    "from scipy import stats\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# Classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('Test-Data\\dgn_raw_data.csv')\n",
    "\n",
    "# Add very small random number to Rating\n",
    "df['target']=df['Rating'].apply(lambda x: x+random.random()/1000)"
   ]
  },
  {
   "source": [
    "## Scenario Regressions (Filtering out effects of Categories)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressions for Each UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique IDs\n",
    "ids = df.UID.unique()\n",
    "\n",
    "# Run linear regressions for each UID\n",
    "op = pd.DataFrame\n",
    "intercept = []\n",
    "coefficients=[]\n",
    "UID = []\n",
    "for p in ids:\n",
    "    df_i = df[df.UID == p]              # Create dataframe for current user id\n",
    "    X = df_i.filter(regex='^[a-zA-Z][0-9]')  # df input variables only\n",
    "    y = df_i['target']                  # Series of target variable\n",
    "    reg = LinearRegression().fit(X, y)  # Fit linear regression\n",
    "    reg.score(X, y)                     # Score regression model\n",
    "    unique_id=df_i['UID'].unique()      # Saves current user id\n",
    "    const = reg.intercept_              # Save intercept of the regression model\n",
    "    coef = reg.coef_                    # Coefficients of regression model\n",
    "    UID.append(unique_id)               # Append current user id\n",
    "    intercept.append(const)             # Append current intercept\n",
    "    coefficients.append(coef)           # Append current regression coefficients\n",
    "\n",
    "# Convert newly created lists into dataframes\n",
    "intercep_new = pd.DataFrame(intercept)\n",
    "coefficients_new = pd.DataFrame(coefficients)\n",
    "UID_new = pd.DataFrame(UID)\n",
    "\n",
    "# Get columns names\n",
    "colNames = df.drop(['Rating', 'target',], axis=1).columns\n",
    "colNames = colNames.insert(1, 'Const')\n",
    "colNames\n",
    "\n",
    "# Concatenate the new dataframes and add column names\n",
    "op = pd.concat([UID_new,intercep_new, coefficients_new], axis=1)\n",
    "op.columns = colNames\n",
    "\n",
    "# Save only regression coefficients for clustering\n",
    "scores = op.drop(['UID','Const'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_dist(x, y):\n",
    "    r = stats.pearsonr(x, y)[0]\n",
    "    return (1 - r) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster on Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('pandas_multiple.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Create dataframe for storing all cluster/variable combo averages and stdevs\n",
    "cls_averages_all = pd.DataFrame()\n",
    "\n",
    "# All maps for all cluster solutions\n",
    "all_maps = []\n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "# Holds only final cluster solutions\n",
    "cluster_solutions = {}\n",
    "\n",
    "max_clusters = 6\n",
    "\n",
    "for n in range(2, max_clusters+1):\n",
    "\n",
    "    # change your df to numpy arr\n",
    "    sample = scores.to_numpy()\n",
    "    \n",
    "    # define a custom metric\n",
    "    metric = distance_metric(type_metric.USER_DEFINED, func=pearson_dist)\n",
    "    \n",
    "    # carry out a km++ init\n",
    "    initial_centers = kmeans_plusplus_initializer(sample, n, random_state=123).initialize()\n",
    "    \n",
    "    # execute kmeans\n",
    "    kmeans_instance = kmeans(sample, initial_centers, metric=metric)\n",
    "    \n",
    "    # run cluster analysis\n",
    "    kmeans_instance.process()\n",
    "    \n",
    "    # get clusters\n",
    "    clusters = kmeans_instance.get_clusters()\n",
    "    \n",
    "    # Empty dataframe to take in cluster assignments for each loop iteration\n",
    "    df_clusters = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(clusters)):\n",
    "        df_scores = scores.iloc[clusters[i],:]\n",
    "        df[f'Optimal {n} cluster solution'] = i+1\n",
    "        df_clusters = pd.concat([df_clusters, df_scores])\n",
    "        df_clusters.sort_index(inplace=True)\n",
    "    \n",
    "    cluster_solutions[f'Optimal {n} cluster solution'] = df_clusters.iloc[:, -1]\n",
    "\n",
    "all_cluster_solutions = pd.DataFrame.from_dict(cluster_solutions)\n",
    "\n",
    "op = op.merge(all_cluster_solutions, left_index=True, right_index=True)\n",
    "\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************************************************#\n",
    "# This is where the classification stuff begins\n",
    "\n",
    "# Column of cluster solutions\n",
    "last_var = op.shape[1]-max_clusters+1   # 18\n",
    "last_cluster = op.shape[1]  # 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************************************************#\n",
    "# Average and Standard Deviations for each cluster/variable combination\n",
    "# For cluster 1 of 2, calculate the average and stdev for each variable\n",
    "# For cluster 2 of 2, calculate the average and stdev for each variable\n",
    "# Etc.\n",
    "\n",
    "for i in range(last_var, last_cluster):\n",
    "    \n",
    "    df_cl = op.iloc[:,np.r_[2:last_var,i]]  # i is the current cluster solution\n",
    "    df_cl_cons = op.iloc[:,np.r_[1:last_var,i]]  # Same as df_cl but with constant\n",
    "\n",
    "    if n == max_clusters:\n",
    "\n",
    "        cls_avg_list = []\n",
    "\n",
    "        # Take the mean of every variable for each cluster\n",
    "        for k in range(1, int(df_cl_cons.iloc[:,-1].max()+1)):\n",
    "            cls_mean = df_cl_cons[df_cl_cons.iloc[:,-1] == k].iloc[:,0:-1].mean()\n",
    "            cls_mean = cls_mean.append(pd.Series({\"Count\":df_cl[df_cl.iloc[:,-1] == k].iloc[:,0:-1].shape[0]}))\n",
    "            cls_avg_list.append(cls_mean)\n",
    "            cls_std = df_cl_cons[df_cl_cons.iloc[:,-1] == k].iloc[:,0:-1].std()\n",
    "            cls_avg_list.append(cls_std)\n",
    "            # NaN means there is either only 1 observation in that cluster or none.\n",
    "\n",
    "        # Convert to dataframe and transpose\n",
    "        cls_averages = pd.DataFrame(cls_avg_list)\n",
    "        cls_averages = cls_averages.T\n",
    "\n",
    "        # Create helpful column names (Cluster # of total_#)\n",
    "        col_names = []\n",
    "\n",
    "        for col in range(1, k+1):\n",
    "            new_name1 = f\"Avg cluster {col}/{k}\"\n",
    "            col_names.append(new_name1)\n",
    "            new_name2 = f\"Std cluster {col}/{k}\"\n",
    "            col_names.append(new_name2)            \n",
    "\n",
    "        # Rename columns\n",
    "        cls_averages.columns = col_names\n",
    "\n",
    "        cls_averages_all = pd.concat([cls_averages_all, cls_averages], axis=1)\n",
    "\n",
    "op.to_excel(writer, index=False, sheet_name=\"All Regressions, Clusters\")\n",
    "\n",
    "\n",
    "# Add averages for all observations to cls_averages_all before exporting\n",
    "all_obs = []\n",
    "\n",
    "# Variable means for all observations\n",
    "all_obs_mean = list(op.filter(regex='^[a-zA-Z][0-9]').mean().values)\n",
    "all_obs_mean.insert(0,op['Const'].mean())\n",
    "all_obs.append(all_obs_mean)\n",
    "\n",
    "# cls_averages_all['new_col'] = pd.Series(list(op.filter(regex='^[a-zA-Z][0-9]').mean().values))\n",
    "\n",
    "# Variable standard deviations for all observations\n",
    "all_obs_std = list(op.filter(regex='^[a-zA-Z][0-9]').std().values)\n",
    "all_obs_std.insert(0,op['Const'].std())\n",
    "all_obs.append(all_obs_std)\n",
    "\n",
    "\n",
    "# Save as dataframe and append to all cls_averages_all dataframe\n",
    "all_obs_cols = list(op.filter(regex='^[a-zA-Z][0-9]').columns)\n",
    "all_obs_cols.insert(0, \"Const\")\n",
    "all_obs_df = pd.DataFrame(all_obs, columns=all_obs_cols)\n",
    "all_obs_df = all_obs_df.T\n",
    "all_obs_cols = ['All obs avg', 'All obs stdev']\n",
    "all_obs_df.columns = all_obs_cols\n",
    "cls_averages_all = pd.concat([cls_averages_all, all_obs_df], axis=1)\n",
    "\n",
    "\n",
    "cls_averages_all.to_excel(writer, sheet_name=\"Cluster Avgs and StDevs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique letters in the Categories\n",
    "category_letters = list(df.filter(regex='^[a-zA-Z][0-9]').columns.str[0].unique())\n",
    "category_letters_numbers = {key: None for key in category_letters}\n",
    "\n",
    "for letter in category_letters:\n",
    "\n",
    "    # List of all variables starting with the current Category letter\n",
    "    letter_list = list(df.loc[:, df.columns.str.startswith(letter)].columns)\n",
    "    number_list = []\n",
    "\n",
    "    # Create a list of the numbers associated with each Category letter\n",
    "    for i in letter_list:\n",
    "        number_list.append(i[1])\n",
    "    \n",
    "    # Add the maximum number of the Category as a value to the Category letter key\n",
    "    category_letters_numbers[letter] = int(max(number_list))\n",
    "\n",
    "all_regressions = []\n",
    "\n",
    "for category in category_letters_numbers:\n",
    "    \n",
    "    all_cat_coefs = {}\n",
    "\n",
    "    # Initial run for A0 (e.g., show only samples when A was omitted)\n",
    "    var_of_interest = category+'0'\n",
    "\n",
    "    vars_of_interest = df.columns.str[0] == category\n",
    "    vars_of_interest = list(df.columns[vars_of_interest])\n",
    "\n",
    "    # Include in df_var if all Categories are 0\n",
    "    df_var = df[(df[vars_of_interest] == 0).all(axis=1)]\n",
    "\n",
    "    # Drop Category columns\n",
    "    df_var = df_var.drop(vars_of_interest, axis=1)\n",
    "\n",
    "    X = df_var.filter(regex='^[a-zA-Z][0-9]')\n",
    "    y = df_var['target']    \n",
    "\n",
    "    # Fit and score model\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    reg.score(X, y)\n",
    "    const = reg.intercept_\n",
    "    coef = list(reg.coef_)\n",
    "    coef.insert(0, const)\n",
    "\n",
    "    all_cat_coefs[var_of_interest] = coef\n",
    "    all_columns = list(X.columns.insert(0,'const'))\n",
    "\n",
    "    # Now do the same regression as above, but isolate each individual variable in the category (e.g., A1, A2, etc.)\n",
    "    for number in range(1,category_letters_numbers[category]+1):\n",
    "        # Isolate the variable of interest\n",
    "        var_of_interest = category+str(number)\n",
    "\n",
    "        # Create dataset with variable of interest == 1\n",
    "        df_var = df[df[var_of_interest] == 1]\n",
    "        \n",
    "        # Filter out the variables from the Category letter\n",
    "        keep_columns = df_var.columns.str[0] != category\n",
    "\n",
    "        df_var = df_var[df_var.columns[keep_columns]]\n",
    "        \n",
    "        # Create predictor and target datasets (and remove UID and Rating)\n",
    "        X = df_var.filter(regex='^[a-zA-Z][0-9]')\n",
    "        y = df_var['target']\n",
    "\n",
    "        # Fit and score model\n",
    "        reg = LinearRegression().fit(X, y)\n",
    "        reg.score(X, y)\n",
    "        const = reg.intercept_\n",
    "        coef = list(reg.coef_)\n",
    "        coef.insert(0, const)\n",
    "\n",
    "        # All coefficients and vars of interest needed (data, columns)\n",
    "        all_cat_coefs[var_of_interest] = coef\n",
    "\n",
    "        # Columns (index)\n",
    "        all_columns = list(X.columns.insert(0,'const'))\n",
    "        \n",
    "\n",
    "    # Put the pieces together\n",
    "    category_df_components = [category, all_cat_coefs, all_columns]\n",
    "\n",
    "    # Add to master list to put into individual dataframes\n",
    "    all_regressions.append(category_df_components)\n",
    "\n",
    "# Put each element of all_regressions into its own dataframe and save to the Excel document\n",
    "\n",
    "for i in all_regressions:\n",
    "    df_category = pd.DataFrame(data=i[1], index=i[2])\n",
    "    df_category.to_excel(writer, index=True, sheet_name=f\"Category {i[0]} Scenarios\")\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd06524d49d688450fc3d47611e48c8230f50bdaae02d55d1a5f70db79bfcaf4363",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}