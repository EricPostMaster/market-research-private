{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "# conda install -c conda-forge scikit-learn-extra\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from operator import itemgetter\n",
    "\n",
    "# Principal Components Analysis\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('dgn_raw_data.csv')\n",
    "\n",
    "# Add very small random number to Rating\n",
    "df['target']=df['Rating'].apply(lambda x: x+random.random()/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressions for Each UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique IDs\n",
    "ids = df.UID.unique()\n",
    "\n",
    "# Run linear regressions for each UID\n",
    "op = pd.DataFrame\n",
    "intercept = []\n",
    "coefficients=[]\n",
    "UID = []\n",
    "for i in ids:\n",
    "    df_i = df[df.UID == i]              # Create dataframe for current user id\n",
    "    X = df_i.drop(['UID','Rating','target'], axis=1)  # df input variables only\n",
    "    y = df_i['target']                  # Series of target variable\n",
    "    reg = LinearRegression().fit(X, y)  # Fit linear regression\n",
    "    reg.score(X, y)                     # Score regression model\n",
    "    unique_id=df_i['UID'].unique()      # Saves current user id\n",
    "    const = reg.intercept_              # Save intercept of the regression model\n",
    "    coef = reg.coef_                    # Coefficients of regression model\n",
    "    UID.append(unique_id)               # Append current user id\n",
    "    intercept.append(const)             # Append current intercept\n",
    "    coefficients.append(coef)           # Append current regression coefficients\n",
    "\n",
    "# Convert newly created lists into dataframes\n",
    "intercep_new = pd.DataFrame(intercept)\n",
    "coefficients_new = pd.DataFrame(coefficients)\n",
    "UID_new = pd.DataFrame(UID)\n",
    "\n",
    "# Get columns names\n",
    "colNames = df.drop(['Rating', 'target',], axis=1).columns\n",
    "colNames = colNames.insert(1, 'Const')\n",
    "colNames\n",
    "\n",
    "# Concatenate the new dataframes and add column names\n",
    "op = pd.concat([UID_new,intercep_new, coefficients_new], axis=1)\n",
    "op.columns = colNames\n",
    "\n",
    "# Save only regression coefficients for clustering\n",
    "scores = op.drop(['UID','Const'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden: Code for the regressions on variable groups A, B, C, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ### Linear Regression with A Variables\n",
    "\n",
    "# # Unique IDs\n",
    "# ids = df.UID.unique()\n",
    "\n",
    "# # Run linear regressions for each UID\n",
    "# op = pd.DataFrame\n",
    "# intercept = []\n",
    "# coefficients=[]\n",
    "# UID = []\n",
    "# for i in ids:\n",
    "#     df_i = df[df.UID == i]              # Create dataframe for current user id\n",
    "#     X = df_i.drop(['UID','B1', 'B2', 'B3', 'B4','C1', 'C2', 'C3', 'C4','D1', 'D2', 'D3', 'D4','Rating','target'], axis=1)  # df input variables only\n",
    "#     y = df_i['target']                  # Series of target variable\n",
    "#     reg = LinearRegression().fit(X, y)  # Fit linear regression\n",
    "#     reg.score(X, y)                     # Score regression model\n",
    "#     unique_id=df_i['UID'].unique()      # Saves current user id\n",
    "#     const = reg.intercept_              # Save intercept of the regression model\n",
    "#     coef = reg.coef_                    # Coefficients of regression model\n",
    "#     UID.append(unique_id)               # Append current user id\n",
    "#     intercept.append(const)             # Append current intercept\n",
    "#     coefficients.append(coef)           # Append current regression coefficients\n",
    "\n",
    "# # Convert newly created lists into dataframes\n",
    "# intercep_new = pd.DataFrame(intercept)\n",
    "# coefficients_new = pd.DataFrame(coefficients)\n",
    "# UID_new = pd.DataFrame(UID)\n",
    "\n",
    "# # Get columns names\n",
    "# colNames = df.drop(['B1', 'B2', 'B3', 'B4','C1', 'C2', 'C3', 'C4','D1', 'D2', 'D3', 'D4','Rating', 'target'], axis=1).columns\n",
    "# colNames = colNames.insert(1, 'Const')\n",
    "# colNames\n",
    "\n",
    "# # Concatenate the new dataframes and add column names\n",
    "# op = pd.concat([UID_new,intercep_new, coefficients_new], axis=1)\n",
    "# op.columns = colNames\n",
    "# op_A = op.iloc[:,2:6]\n",
    "\n",
    "\n",
    "# #******************************************************************************#\n",
    "# ### Linear Regression with B Variables\n",
    "\n",
    "# # Unique IDs\n",
    "# ids = df.UID.unique()\n",
    "\n",
    "# # Run linear regressions for each UID\n",
    "# op = pd.DataFrame\n",
    "# intercept = []\n",
    "# coefficients=[]\n",
    "# UID = []\n",
    "# for i in ids:\n",
    "#     df_i = df[df.UID == i]              # Create dataframe for current user id\n",
    "#     X = df_i.drop(['UID','A1', 'A2', 'A3', 'A4','C1', 'C2', 'C3', 'C4','D1', 'D2', 'D3', 'D4','Rating','target'], axis=1)  # df input variables only\n",
    "#     y = df_i['target']                  # Series of target variable\n",
    "#     reg = LinearRegression().fit(X, y)  # Fit linear regression\n",
    "#     reg.score(X, y)                     # Score regression model\n",
    "#     unique_id=df_i['UID'].unique()      # Saves current user id\n",
    "#     const = reg.intercept_              # Save intercept of the regression model\n",
    "#     coef = reg.coef_                    # Coefficients of regression model\n",
    "#     UID.append(unique_id)               # Append current user id\n",
    "#     intercept.append(const)             # Append current intercept\n",
    "#     coefficients.append(coef)           # Append current regression coefficients\n",
    "\n",
    "# # Convert newly created lists into dataframes\n",
    "# intercep_new = pd.DataFrame(intercept)\n",
    "# coefficients_new = pd.DataFrame(coefficients)\n",
    "# UID_new = pd.DataFrame(UID)\n",
    "\n",
    "# # Get columns names\n",
    "# colNames = df.drop(['A1', 'A2', 'A3', 'A4','C1', 'C2', 'C3', 'C4','D1', 'D2', 'D3', 'D4','Rating', 'target'], axis=1).columns\n",
    "# colNames = colNames.insert(1, 'Const')\n",
    "# colNames\n",
    "\n",
    "# # Concatenate the new dataframes and add column names\n",
    "# op = pd.concat([UID_new,intercep_new, coefficients_new], axis=1)\n",
    "# op.columns = colNames\n",
    "# op_B = op.iloc[:,2:6]\n",
    "\n",
    "\n",
    "# #******************************************************************************#\n",
    "# ### Linear Regression with C Variables\n",
    "\n",
    "# # Unique IDs\n",
    "# ids = df.UID.unique()\n",
    "\n",
    "# # Run linear regressions for each UID\n",
    "# op = pd.DataFrame\n",
    "# intercept = []\n",
    "# coefficients=[]\n",
    "# UID = []\n",
    "# for i in ids:\n",
    "#     df_i = df[df.UID == i]              # Create dataframe for current user id\n",
    "#     X = df_i.drop(['UID', 'A1', 'A2', 'A3', 'A4', 'B1', 'B2', 'B3', 'B4', 'D1', 'D2', 'D3', 'D4', 'Rating', 'target'], axis=1)  # df input variables only\n",
    "#     y = df_i['target']                  # Series of target variable\n",
    "#     reg = LinearRegression().fit(X, y)  # Fit linear regression\n",
    "#     reg.score(X, y)                     # Score regression model\n",
    "#     unique_id=df_i['UID'].unique()      # Saves current user id\n",
    "#     const = reg.intercept_              # Save intercept of the regression model\n",
    "#     coef = reg.coef_                    # Coefficients of regression model\n",
    "#     UID.append(unique_id)               # Append current user id\n",
    "#     intercept.append(const)             # Append current intercept\n",
    "#     coefficients.append(coef)           # Append current regression coefficients\n",
    "\n",
    "# # Convert newly created lists into dataframes\n",
    "# intercep_new = pd.DataFrame(intercept)\n",
    "# coefficients_new = pd.DataFrame(coefficients)\n",
    "# UID_new = pd.DataFrame(UID)\n",
    "\n",
    "# # Get columns names\n",
    "# colNames = df.drop(['A1', 'A2', 'A3', 'A4', 'B1', 'B2', 'B3', 'B4', 'D1', 'D2', 'D3', 'D4', 'Rating', 'target'], axis=1).columns\n",
    "# colNames = colNames.insert(1, 'Const')\n",
    "# colNames\n",
    "\n",
    "# # Concatenate the new dataframes and add column names\n",
    "# op = pd.concat([UID_new,intercep_new, coefficients_new], axis=1)\n",
    "# op.columns = colNames\n",
    "# op_C = op.iloc[:,2:6]\n",
    "\n",
    "\n",
    "\n",
    "# #******************************************************************************#\n",
    "# ### Linear Regression with D Variables\n",
    "\n",
    "# # Unique IDs\n",
    "# ids = df.UID.unique()\n",
    "\n",
    "# # Run linear regressions for each UID\n",
    "# op = pd.DataFrame\n",
    "# intercept = []\n",
    "# coefficients=[]\n",
    "# UID = []\n",
    "# for i in ids:\n",
    "#     df_i = df[df.UID == i]              # Create dataframe for current user id\n",
    "#     X = df_i.drop(['UID', 'A1', 'A2', 'A3', 'A4', 'B1', 'B2', 'B3', 'B4', 'C1', 'C2', 'C3', 'C4', 'Rating', 'target'], axis=1)  # df input variables only\n",
    "#     y = df_i['target']                  # Series of target variable\n",
    "#     reg = LinearRegression().fit(X, y)  # Fit linear regression\n",
    "#     reg.score(X, y)                     # Score regression model\n",
    "#     unique_id=df_i['UID'].unique()      # Saves current user id\n",
    "#     const = reg.intercept_              # Save intercept of the regression model\n",
    "#     coef = reg.coef_                    # Coefficients of regression model\n",
    "#     UID.append(unique_id)               # Append current user id\n",
    "#     intercept.append(const)             # Append current intercept\n",
    "#     coefficients.append(coef)           # Append current regression coefficients\n",
    "\n",
    "# # Convert newly created lists into dataframes\n",
    "# intercep_new = pd.DataFrame(intercept)\n",
    "# coefficients_new = pd.DataFrame(coefficients)\n",
    "# UID_new = pd.DataFrame(UID)\n",
    "\n",
    "# # Get columns names\n",
    "# colNames = df.drop(['A1', 'A2', 'A3', 'A4', 'B1', 'B2', 'B3', 'B4', 'C1', 'C2', 'C3', 'C4', 'Rating', 'target'], axis=1).columns\n",
    "# colNames = colNames.insert(1, 'Const')\n",
    "# colNames\n",
    "\n",
    "# # Concatenate the new dataframes and add column names\n",
    "# op = pd.concat([UID_new,intercep_new, coefficients_new], axis=1)\n",
    "# op.columns = colNames\n",
    "# op_D = op.iloc[:,2:6]\n",
    "\n",
    "\n",
    "# #******************************************************************************#\n",
    "# ### Replace 1's w/ Regression Coefficients in Original Data\n",
    "\n",
    "# # Concatenate regression dataframes\n",
    "# all_cfs = pd.concat([op_A, op_B, op_C, op_D], axis=1)\n",
    "\n",
    "# # Replace 1's w/ regression coefficients by column\n",
    "# cfs_cols = all_cfs.columns\n",
    "\n",
    "# for col in cfs_cols:\n",
    "#     for i in range(1,len(all_cfs)+1):\n",
    "#         df.loc[df['UID'] == i,[col]] = df.loc[df['UID'] == i,[col]].replace(1,all_cfs.loc[i-1,col])\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#******************************************************************************#\n",
    "# Comparing covariance and correlation PCA.  We should do correlation PCA.\n",
    "\n",
    "# Create PCA dataframe\n",
    "df_fct = op.drop(['UID','Const'], axis=1)\n",
    "\n",
    "# Standardize df_fct\n",
    "# df_pca = stats.zscore(df_fct)  # Didn't need to worry about standardizing.\n",
    "# Could build in a correlation/covariance PCA thing using ranges of the variables\n",
    "\n",
    "# Create PCA object\n",
    "pca = PCA(random_state=123)\n",
    "\n",
    "# Get principal components\n",
    "pca.fit(df_fct)\n",
    "\n",
    "# Get scores\n",
    "pca.transform(df_fct)\n",
    "\n",
    "# Components needed\n",
    "pcs_needed = len(np.where(pca.explained_variance_ >= 1)[0])\n",
    "\n",
    "# Save scores for PCs w/ eignvalues >=1 as dataframe for clustering\n",
    "scores = pd.DataFrame(pca.transform(df_fct))\n",
    "scores = scores.iloc[:,0:pcs_needed]\n",
    "\n",
    "# How many observations\n",
    "n_samples = pca.components_.shape[0]\n",
    "\n",
    "# Transpose the principal components\n",
    "murph = pca.components_.T\n",
    "# Center the data\n",
    "murph -= np.mean(murph, axis=0)\n",
    "# Compute the covariance matrix\n",
    "cov_matrix = np.dot(murph.T, murph) / n_samples\n",
    "\n",
    "for eigenvector in pca.components_:\n",
    "    print(np.dot(eigenvector.T, np.dot(cov_matrix, eigenvector)))\n",
    "\n",
    "n_samples = df_fct.shape[0]\n",
    "\n",
    "pca = PCA(random_state=123)\n",
    "X_transformed = pca.fit_transform(df_fct)\n",
    "\n",
    "# This is the explained variance.  They are big numbers because this is Cov. PCA\n",
    "X_centered = df_fct - np.mean(df_fct, axis=0)\n",
    "cov_matrix = np.dot(X_centered.T, X_centered) / n_samples\n",
    "eigenvalues = pca.explained_variance_\n",
    "for eigenvalue, eigenvector in zip(eigenvalues, pca.components_):\n",
    "    print(eigenvalue)\n",
    "\n",
    "# This is the same thing as the code above but built into sklearn\n",
    "pca.explained_variance_\n",
    "# These are the eigenvalues of the covariance matrix\n",
    "# They don't have values near 1-ish, so I need to understand why.\n",
    "\n",
    "\n",
    "#******************************************************************************#\n",
    "# Biplots for comparing correlation and covariance PCA for this data\n",
    "\n",
    "# !pip install pca\n",
    "from pca import pca\n",
    "\n",
    "# Correlation PCA & biplot\n",
    "model = pca(n_components=4)\n",
    "results = model.fit_transform(df_pca)\n",
    "fig, ax = model.biplot(n_feat=16, cmap=None, label=False, legend=False)\n",
    "\n",
    "# Covariance PCA & biplot\n",
    "model2 = pca(n_components=4)\n",
    "results2 = model2.fit_transform(df_fct)\n",
    "fig, ax = model2.biplot(n_feat=16, cmap=None, label=False, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components Used: 4\n",
      "Variance Explained: 72.67%\n"
     ]
    }
   ],
   "source": [
    "# # Create PCA dataframe\n",
    "# df_fct = op.drop(['UID','Const'], axis=1)\n",
    "\n",
    "# # Standardize df_fct - Need to standardize to use eigenvalues >= 1\n",
    "# df_fct = stats.zscore(df_fct)\n",
    "\n",
    "# # Create PCA object\n",
    "# pca = PCA(random_state=123)\n",
    "\n",
    "# # Get principal components & scores\n",
    "# pca.fit_transform(df_fct)\n",
    "\n",
    "# # Components needed\n",
    "# pcs_needed = len(np.where(pca.explained_variance_ >= 1)[0])\n",
    "\n",
    "# # Save scores for PCs w/ eignvalues >=1 as dataframe for clustering\n",
    "# scores = pd.DataFrame(pca.transform(df_fct))\n",
    "# scores = scores.iloc[:,0:pcs_needed]\n",
    "# expl_var = round(pca.explained_variance_ratio_.cumsum()[pcs_needed-1]*100, 2)\n",
    "\n",
    "# print(\"Principal Components Used: \", pcs_needed, sep='')\n",
    "# print(\"Variance Explained: \", expl_var, \"%\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster on Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('pandas_multiple.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# All maps for all cluster solutions\n",
    "all_maps = []\n",
    "\n",
    "# Column of last cluster solution\n",
    "last_var = op.shape[1]\n",
    "\n",
    "for i in range(2,7):\n",
    "    \n",
    "    sw = []\n",
    "    \n",
    "    # Create clustering objects\n",
    "    cls1 = KMeans(n_clusters=i, random_state=0)\n",
    "    cls2 = KMedoids(n_clusters=i, random_state=0)\n",
    "    cls3 = AgglomerativeClustering(n_clusters=i,\n",
    "                                   affinity='euclidean',\n",
    "                                   linkage='ward')\n",
    "        # Agglomerative clustering: if linkage=ward, affinity must be Euclidean\n",
    "    cls_algs = [['kMeans', cls1],\n",
    "                ['kMedoids', cls2],\n",
    "                ['Hierarchical', cls3]]\n",
    "    \n",
    "    # Fit and score clustering solutions for i clusters w/ each algorithm\n",
    "    for cls in cls_algs:\n",
    "        \n",
    "        # Fit the model to the factor analysis scores\n",
    "        cls[1].fit(scores)\n",
    "        \n",
    "        # List of assigned clusters\n",
    "        clusters = cls[1].fit_predict(scores)\n",
    "        \n",
    "        # Silhouette scores for each solution\n",
    "        silhouette_avg = silhouette_score(scores,clusters)\n",
    "        \n",
    "        # Store solution info\n",
    "        algorithm = cls[0]\n",
    "        i_stats = [algorithm, i, silhouette_avg, clusters]\n",
    "        sw.append(i_stats)\n",
    "\n",
    "    # Reorder cluster lists by descending silhouette scores.\n",
    "    # Clusters in first element should be assigned to training data.\n",
    "    sw = sorted(sw, key=itemgetter(2), reverse=True)\n",
    "    op[f'Optimal {sw[0][1]} cluster solution ({sw[0][0]})'] = sw[0][3]\n",
    "\n",
    "    # This is the big for loop\n",
    "    for i in range(18, last_var):\n",
    "        df_cl = op.iloc[:,np.r_[2:18,i]]  # i is the current cluster solution\n",
    "\n",
    "        #**********************************************************************#\n",
    "\n",
    "        # Split data into 70% training, 30% validation\n",
    "        train, valid = train_test_split(df_cl, test_size=0.30, random_state=123)\n",
    "\n",
    "        # X is unlabeled training data, y is true training labels \n",
    "        X, y = train.iloc[:,0:-1], train.iloc[:,-1]\n",
    "\n",
    "        X_valid, y_valid = valid.iloc[:,0:-1], valid.iloc[:,-1]\n",
    "\n",
    "        #**********************************************************************#\n",
    "\n",
    "        # Get variable importances\n",
    "\n",
    "        clf1 = RandomForestClassifier(random_state=0)\n",
    "        clf2 = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "        classifiers = [['rf', clf1], ['gbt', clf2]]\n",
    "\n",
    "        for classifier in classifiers:    \n",
    "            # Fit classifier to training data\n",
    "            classifier[1].fit(X,y)    \n",
    "\n",
    "        # Create variable importance dataframe\n",
    "        num_vars = list(range(1,len(clf1.feature_importances_)+1))\n",
    "        importance = pd.DataFrame({'variable': num_vars,\n",
    "                                   'rf': clf1.feature_importances_,\n",
    "                                   'gbt': clf2.feature_importances_,})\n",
    "\n",
    "        # Average variable importance of rf and gbt models\n",
    "        importance['avg'] = (importance['rf']+importance['gbt'])/2\n",
    "\n",
    "        # Put avg importances on a scale from 0 to 1 to make it easier to visualize\n",
    "        importance['Relative Importance'] = np.interp(importance['avg'],\n",
    "                                                      (importance['avg'].min(),\n",
    "                                                       importance['avg'].max()),\n",
    "                                                      (0, 1))\n",
    "\n",
    "        # View top 10 variables when RF and GBT models are averaged\n",
    "        top_10_avg = importance.sort_values(by='avg', ascending=False)[['avg','Relative Importance']].head(10)\n",
    "\n",
    "        # Add variable rank column to dataframe\n",
    "        importance_rank = num_vars\n",
    "        importance = importance.sort_values(by='Relative Importance', ascending=False)\n",
    "        importance['rank'] = importance_rank\n",
    "        importance.reset_index(inplace=True)\n",
    "\n",
    "        # Save index of top 5 variables (not the variable number!)\n",
    "        top_5 = importance[importance['rank'] <= 5]['index']\n",
    "\n",
    "        #**********************************************************************#\n",
    "        # Convert data to binary, train classifiers, score validation, create maps\n",
    "\n",
    "        # Convert X, X_valid, and df_cl predictors to all 1 and -1\n",
    "        X = (X.mask(df > 0, other=1, inplace=False)\n",
    "             .mask(df <= 0, other=-1, inplace=False))\n",
    "        X_valid = (X_valid.mask(df > 0, other=1, inplace=False)\n",
    "                   .mask(df <= 0, other=-1, inplace=False))\n",
    "        all_data_masked = (df_cl.iloc[:,0:-1].mask(df > 0, other=1, inplace=False)\n",
    "                           .mask(df <= 0, other=-1, inplace=False))\n",
    "\n",
    "        map_collection = []\n",
    "\n",
    "        # Retrain on the 2-5 most important variables\n",
    "        for j in range(2,6):\n",
    "\n",
    "            clf_scores = []\n",
    "\n",
    "            clf1 = RandomForestClassifier(random_state=0)\n",
    "            clf2 = GradientBoostingClassifier(random_state=0)\n",
    "            clf3 = SVC(random_state=0)\n",
    "            clf4 = KNeighborsClassifier()\n",
    "\n",
    "            classifiers = [['rf', clf1], ['gbt', clf2], ['svc', clf3], ['knn', clf4]]\n",
    "\n",
    "            for classifier in classifiers:\n",
    "\n",
    "                # Fit classifier to training data\n",
    "                classifier[1].fit(X.iloc[:,np.r_[top_5[0:j]]],y)\n",
    "\n",
    "                # Store classifier-specific results [algorithm object, classifier name, scores]\n",
    "                results = [classifier[1],\n",
    "                           classifier[0],\n",
    "                           classifier[1].score(X_valid.iloc[:,np.r_[top_5[0:j]]],y_valid)]\n",
    "\n",
    "                # Overall classifier results\n",
    "                clf_scores.append(results)\n",
    "\n",
    "            # Sort classifier accuracy in descending order\n",
    "            clf_scores = sorted(clf_scores, key=itemgetter(2), reverse=True)\n",
    "            # clf_scores[0][0] is the best model\n",
    "            \n",
    "            # Fit the best model on all data\n",
    "            best_model = clf_scores[0][0].fit(all_data_masked.iloc[:,np.r_[top_5[0:j]]], df_cl.iloc[:,-1])\n",
    "\n",
    "            # Score validation data, get predictions\n",
    "#             X_valid_sub = X_valid.iloc[:,np.r_[top_5[0:j]]]\n",
    "#             score = clf_scores[0][0].score(X_valid_sub, y_valid)\n",
    "#             preds = clf_scores[0][0].predict(X_valid_sub)\n",
    "\n",
    "            # Create mappings\n",
    "            \n",
    "            # Creates grid of dimension j\n",
    "            grid = pd.DataFrame(list(itertools.product([-1,1], repeat=j)))\n",
    "\n",
    "            # This is the best model predicting the grid\n",
    "            preds = best_model.predict(grid)\n",
    "\n",
    "            # Add to grid dataframe\n",
    "            grid['preds'] = preds\n",
    "\n",
    "            # Change grid to mapping to fit into the rest of the code\n",
    "            mapping = grid\n",
    "\n",
    "            # Save current mapping to map collection for this cluster solution\n",
    "            map_collection.append(mapping)\n",
    "\n",
    "            # Write each dataframe to a different worksheet.\n",
    "            mapping.to_excel(writer, sheet_name=f\"{df_cl.columns[-1][8:17]}s, {j} vars\")\n",
    "\n",
    "        all_maps.append(map_collection)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_scores[0][0].fit(murph, df_cl.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "murph = (df_cl.iloc[:,0:-1].mask(df > 0, other=1, inplace=False)\n",
    "         .mask(df <= 0, other=-1, inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     0\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "     ..\n",
       "95    1\n",
       "96    1\n",
       "97    1\n",
       "98    1\n",
       "99    1\n",
       "Name: Optimal 2 cluster solution (kMeans), Length: 100, dtype: int32"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates grid of dimension j\n",
    "grid = pd.DataFrame(list(itertools.product([-1,1], repeat=j)))\n",
    "\n",
    "# This is the best model predicting the grid\n",
    "preds = clf_scores[0][0].predict(grid)\n",
    "\n",
    "# Add to grid dataframe\n",
    "grid['preds'] = preds\n",
    "\n",
    "# Change grid to mapping to fit into the rest of the code\n",
    "mapping = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to create a new dataset for each clustering solution\n",
    "# I could create a separate dataframe of clustering solutions, each with the original variables and 1 clustering solution\n",
    "# Then I split the first dataset\n",
    "# Then I run it through the classifier loop\n",
    "# I get the variable importance\n",
    "# Save the top 5 variables\n",
    "# Train the classifier on the top 2 variables\n",
    "\n",
    "# 2 clusters, 2 variables\n",
    "# Every 1,1 combination needs to be classified the same\n",
    "# Every 1,-1 combination needs to be classified the same\n",
    "\n",
    "# Use a NumPy meshgrid to map out all possible 1,-1 combinations\n",
    "# Should end up with 25 different maps (5 cluster solutions with 5 variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for making the letter-based regression dynamic\n",
    "\n",
    "# Create a list of unique first letters of variables\n",
    "X = df.drop(['UID','Rating','target'], axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "var_letters = []\n",
    "\n",
    "for i in X.columns:\n",
    "    var_letters.append(i[0:1])  # Append first character\n",
    "\n",
    "var_letters = list(np.unique(var_letters))  # List of unique variable letters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Scenario Analysis</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>Rating</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UID  A1  A2  A3  A4  B1  B2  B3  B4  C1  C2  C3  C4  D1  D2  D3  D4  \\\n",
       "0    1   1   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0   \n",
       "1    1   1   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   \n",
       "2    1   0   0   0   1   0   0   0   1   1   0   0   0   0   0   0   0   \n",
       "3    1   0   1   0   0   0   0   0   0   0   0   0   1   0   1   0   0   \n",
       "4    1   0   1   0   0   0   0   1   0   0   1   0   0   0   0   0   1   \n",
       "\n",
       "   Rating      target  \n",
       "0     100  100.000507  \n",
       "1     100  100.000668  \n",
       "2       0    0.000386  \n",
       "3       0    0.000067  \n",
       "4       0    0.000382  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(condition, value if condition is true, value if condition is false)\n",
    "\n",
    "# create a list of the column categories\n",
    "\n",
    "cat_A = ['A1', 'A2', 'A3', 'A4']\n",
    "cat_B = ['B1', 'B2', 'B3', 'B4']\n",
    "cat_C = ['C1', 'C2', 'C3', 'C4']\n",
    "cat_D = ['D1', 'D2', 'D3', 'D4']\n",
    "\n",
    "# create a list of our conditions\n",
    "cat_A_conditions = [\n",
    "    (df['A1'] == 1),\n",
    "    (df['A2'] == 1),\n",
    "    (df['A3'] == 1),\n",
    "    (df['A4'] == 1),\n",
    "    (df['A1']==0) & (df['A2']==0) & (df['A3']==0) & (df['A4']==0),\n",
    "    ]\n",
    "\n",
    "cat_B_conditions = [    \n",
    "    (df['B1'] == 1),\n",
    "    (df['B2'] == 1),\n",
    "    (df['B3'] == 1),\n",
    "    (df['B4'] == 1),\n",
    "    (df['B1']==0) & (df['B2']==0) & (df['B3']==0) & (df['B4']==0),\n",
    "    ]    \n",
    "\n",
    "cat_C_conditions = [    \n",
    "    (df['C1'] == 1),\n",
    "    (df['C2'] == 1),\n",
    "    (df['C3'] == 1),\n",
    "    (df['C4'] == 1),\n",
    "    (df['C1']==0) & (df['C2']==0) & (df['C3']==0) & (df['C4']==0),\n",
    "    ]\n",
    "\n",
    "cat_D_conditions = [    \n",
    "    (df['D1'] == 1),\n",
    "    (df['D2'] == 1),\n",
    "    (df['D3'] == 1),\n",
    "    (df['D4'] == 1),  \n",
    "    (df['D1']==0) & (df['D2']==0) & (df['D3']==0) & (df['D4']==0),\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "cat_A_values = ['A1', 'A2', 'A3', 'A4', 'A0']\n",
    "cat_B_values = ['B1', 'B2', 'B3', 'B4','B0']\n",
    "cat_C_values = ['C1', 'C2', 'C3', 'C4','C0']\n",
    "cat_D_values = ['D1', 'D2', 'D3', 'D4','D0']\n",
    "    \n",
    "df['cat_A_scenario'] = np.select(cat_A_conditions, cat_A_values)\n",
    "df['cat_B_scenario'] = np.select(cat_B_conditions, cat_B_values)\n",
    "df['cat_C_scenario'] = np.select(cat_C_conditions, cat_C_values)\n",
    "df['cat_D_scenario'] = np.select(cat_D_conditions, cat_D_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Example of Scenario where Variable A1 has a 1 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_A = df['cat_A_scenario'].unique()\n",
    "# list of independant variables for regression\n",
    "fields = df.columns[1:17]\n",
    "dep_var = df['noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>C1</th>\n",
       "      <th>...</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>Rating</th>\n",
       "      <th>noise</th>\n",
       "      <th>cat_A_scenario</th>\n",
       "      <th>cat_B_scenario</th>\n",
       "      <th>cat_C_scenario</th>\n",
       "      <th>cat_D_scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000893</td>\n",
       "      <td>A1</td>\n",
       "      <td>B4</td>\n",
       "      <td>C1</td>\n",
       "      <td>D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000783</td>\n",
       "      <td>A1</td>\n",
       "      <td>B3</td>\n",
       "      <td>C0</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000825</td>\n",
       "      <td>A1</td>\n",
       "      <td>B0</td>\n",
       "      <td>C1</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>A1</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>100.000252</td>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C3</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000552</td>\n",
       "      <td>A1</td>\n",
       "      <td>B4</td>\n",
       "      <td>C0</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000693</td>\n",
       "      <td>A1</td>\n",
       "      <td>B3</td>\n",
       "      <td>C2</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000722</td>\n",
       "      <td>A1</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000264</td>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C4</td>\n",
       "      <td>D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000156</td>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C4</td>\n",
       "      <td>D0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UID  A1  A2  A3  A4  B1  B2  B3  B4  C1  ...  D1  D2  D3  D4  Rating  \\\n",
       "0       1   1   0   0   0   0   0   0   1   1  ...   0   0   0   0     100   \n",
       "1       1   1   0   0   0   0   0   1   0   0  ...   1   0   0   0     100   \n",
       "13      1   1   0   0   0   0   0   0   0   1  ...   0   0   0   1     100   \n",
       "16      1   1   0   0   0   0   0   0   1   0  ...   0   0   1   0       0   \n",
       "17      1   1   0   0   0   1   0   0   0   0  ...   0   0   0   1     100   \n",
       "...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..     ...   \n",
       "2383  100   1   0   0   0   0   0   0   1   0  ...   0   0   0   1       5   \n",
       "2385  100   1   0   0   0   0   0   1   0   0  ...   0   0   1   0       5   \n",
       "2393  100   1   0   0   0   0   0   0   1   0  ...   0   1   0   0       5   \n",
       "2398  100   1   0   0   0   1   0   0   0   0  ...   0   0   0   0       5   \n",
       "2399  100   1   0   0   0   1   0   0   0   0  ...   0   0   0   0       5   \n",
       "\n",
       "           noise  cat_A_scenario  cat_B_scenario  cat_C_scenario  \\\n",
       "0     100.000893              A1              B4              C1   \n",
       "1     100.000783              A1              B3              C0   \n",
       "13    100.000825              A1              B0              C1   \n",
       "16      0.000479              A1              B4              C4   \n",
       "17    100.000252              A1              B1              C3   \n",
       "...          ...             ...             ...             ...   \n",
       "2383    5.000552              A1              B4              C0   \n",
       "2385    5.000693              A1              B3              C2   \n",
       "2393    5.000722              A1              B4              C4   \n",
       "2398    5.000264              A1              B1              C4   \n",
       "2399    5.000156              A1              B1              C4   \n",
       "\n",
       "     cat_D_scenario  \n",
       "0                D0  \n",
       "1                D1  \n",
       "13               D4  \n",
       "16               D3  \n",
       "17               D4  \n",
       "...             ...  \n",
       "2383             D4  \n",
       "2385             D3  \n",
       "2393             D2  \n",
       "2398             D0  \n",
       "2399             D0  \n",
       "\n",
       "[513 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A1 = df[df['cat_A_scenario']=='A1']\n",
    "df_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.91035518762444\n",
      "[ -3.84235504 -13.45891789  -5.98115784  -1.00151876  -5.2084735\n",
      "  -0.95495595  -3.15645822  -7.2888877   -2.32297686  -3.7339574\n",
      "  -5.08132817   1.23153583]\n"
     ]
    }
   ],
   "source": [
    "X =df_A1[['B1', 'B2', 'B3', 'B4','C1', 'C2', 'C3', 'C4','D1', 'D2', 'D3', 'D4']]\n",
    "y= df_A1['noise']\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)\n",
    "const = reg.intercept_\n",
    "coef = reg.coef_\n",
    "print(const)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratch pad, not finished\n",
    "for i in cat_A:\n",
    "    df_i = df[df.cat_A_scenario == i]\n",
    "    X =df_i[df_i.columns[1:17]]\n",
    "    y= df_i['noise']\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    reg.score(X, y)\n",
    "    const = reg.intercept_\n",
    "    coef = reg.coef_\n",
    "    intercept.append(const)\n",
    "    coefficients.append(coef)\n",
    "#print(UID)    \n",
    "intercep_new = pd.DataFrame(intercept)\n",
    "coefficients_new = pd.DataFrame(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
